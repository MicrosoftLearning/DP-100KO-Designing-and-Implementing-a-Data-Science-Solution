{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 파이프라인 만들기\r\n",
        "\r\n",
        "Azure ML SDK를 사용해 스크립트 기반 실험을 실행하면 데이터를 수집하고 모델을 학습시킨 다음 개별적으로 등록하는 데 필요한 여러 단계를 수행할 수 있습니다. 그러나 엔터프라이즈 환경에서는 보통 기계 학습 솔루션을 빌드하려면 수행해야 하는 개별 단계 순서를 *파이프라인*에 캡슐화합니다. 이 파이프라인은 사용자의 요청 시 컴퓨팅 대상 하나 이상에서 실행하거나, 자동화된 빌드 프로세스에서 실행하거나 일정에 따라 실행할 수 있습니다.\r\n",
        "\r\n",
        "이 Notebook에서는 이러한 모든 요소를 취합하여 데이터를 전처리한 다음 모델 학습과 등록을 진행하는 간단한 파이프라인을 만들어 보겠습니다.\r\n",
        "\r\n",
        "## Azure Machine Learning SDK 설치\r\n",
        "\r\n",
        "Azure Machine Learning SDK는 자주 업데이트됩니다. 다음 셀을 실행하여 최신 릴리스로 업그레이드하고 Notebook 위젯을 지원하는 추가 패키지를 다운로드하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade azureml-sdk azureml-widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 작업 영역에 연결합니다.\r\n",
        "\r\n",
        "최신 버전의 SDK를 설치했으므로 작업 영역에 연결할 수 있습니다.\r\n",
        "\r\n",
        "> **참고**: Azure 구독에 인증된 세션을 아직 설정하지 않은 경우에는 링크를 클릭하고 인증 코드를 입력한 다음 Azure에 로그인하여 인증을 하라는 메시지가 표시됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# 저장된 구성 파일에서 작업 영역 로드\r\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 준비\r\n",
        "\r\n",
        "파이프라인에서는 당뇨병 환자의 세부 정보가 포함된 데이터 세트를 사용합니다. 아래 셀을 실행하여 이 데이터 세트를 만듭니다. 이전에 데이터 세트를 만든 경우, 코드가 기존 버전을 찾습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # /data에서 당뇨병 CSV 파일 업로드\n",
        "                        target_path='diabetes-data/', # 데이터 저장소의 폴더 경로에 해당 파일 저장\n",
        "                        overwrite=True, # 이름이 같은 기존 파일 바꾸기\n",
        "                        show_progress=True)\n",
        "\n",
        "    #데이터 저장소의 경로에서 테이블 형식 데이터 세트 만들기(시간이 다소 걸릴 수 있음)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # 테이블 형식 데이터 세트 등록\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파이프라인 단계용 스크립트 만들기\r\n",
        "\r\n",
        "파이프라인은 *단계* 하나 이상으로 구성됩니다. 이러한 단계는 Python 스크립트일 수도 있고, 특정 위치 간에 데이터를 복사하는 데이터 전송 단계 등의 특수 단계일 수도 있습니다.  이 연습에서는 Python 스크립트 단계 2개가 포함된 간단한 파이프라인을 작성합니다. 한 단계에서는 학습 데이터를 전처리하며, 다른 단계에서는 전처리된 데이터를 사용하여 모델 학습과 등록을 진행합니다.\r\n",
        "\r\n",
        "먼저 파이프라인 단계에서 사용할 스크립트 파일용 폴더를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# 파이프라인 단계 파일용 폴더 만들기\r\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 첫 번째 스크립트를 작성합니다. 이 스크립트는 당뇨병 데이터 세트의 데이터를 읽은 후 간단한 전처리 작업을 적용해 데이터가 누락된 행을 제거하고 숫자 특징을 크기가 비슷하도록 정규화합니다.\r\n",
        "\r\n",
        "이 스크립트에 포함된 **--prepped-data** 인수는 결과 데이터를 저장해야 하는 폴더를 참조합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# 라이브러리 가져오기\r\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 매개 변수 가져오기\r\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# 실험 실행 컨텍스트 가져오기\r\n",
        "run = Run.get_context()\n",
        "\n",
        "# 데이터 로드(입력 데이터 세트로 전달됨)\r\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# 원시 행 수 로깅\r\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# Null 제거\r\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# 숫자 열 정규화\r\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# 처리된 행 로깅\r\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# 준비된 데이터 저장\r\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# 실행 종료\r\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 두 번째 단계(모델 학습)용 스크립트를 만들 수 있습니다. 이 스크립트에 포함된 **--training-folder** 인수는 이전 단계에서 준비한 데이터가 저장된 폴더를 참조합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# 라이브러리 가져오기\r\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 매개 변수 가져오기\r\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
        "args = parser.parse_args()\n",
        "training_folder = args.training_folder\n",
        "\n",
        "# 실험 실행 컨텍스트 가져오기\r\n",
        "run = Run.get_context()\n",
        "\n",
        "# 학습 폴더에 준비된 데이터 파일 로드\r\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_folder,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# 기능 및 레이블 분리\r\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# 데이터를 학습 세트와 테스트 세트로 분할\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# 의사 결정 트리 모델 학습 진행\r\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# 정확도 계산\r\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# AUC 계산\r\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# ROC 곡선 그리기\r\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# 대각선 50% 선 그리기\r\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# 모델의 FPR 및 TPR 그리기\r\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# outputs 폴더에 학습된 모델 저장\r\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# 모델 등록\r\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파이프라인 단계용 컴퓨팅 환경 준비\r\n",
        "\r\n",
        "이 연습에서는 두 단계에 같은 컴퓨팅을 사용하지만 각 단계는 독립적으로 실행됩니다. 따라서 해당하는 경우 각 단계에 서로 다른 컴퓨팅 컨텍스트를 지정할 수 있습니다.\r\n",
        "\r\n",
        "먼저, 이전 랩에서 만든 컴퓨팅 대상을 가져옵니다. 없는 경우에는 생성됩니다.\r\n",
        "\r\n",
        "> **중요**: 계산 클러스터를 실행하기 전에 *your-compute-cluster*를 아래 코드에서 컴퓨팅 클러스터의 이름으로 변경하세요! 클러스터 이름은 길이가 2~16자 사이의 전역으로 고유한 이름이어야 합니다. 유효한 문자는 문자, 숫자 및 문자입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"dp100-cluster\"\n",
        "\n",
        "try:\n",
        "    # 기존 컴퓨팅 대상 확인\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # 아직 존재하지 않는 경우, 생성합니다.\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "컴퓨팅에는 필요한 패키지 종속성이 설치된 Python 환경이 필요하므로 실행 구성을 만들어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# 실험용 Python 환경 만들기\r\n",
        "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
        "diabetes_env.python.user_managed_dependencies = False # Azure ML의 종속성 관리 허용\n",
        "diabetes_env.docker.enabled = True # Docker 컨테이너 사용\n",
        "\n",
        "# 패키지 종속성 집합 만들기\r\n",
        "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
        "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
        "\n",
        "# 환경에 종속성 추가\r\n",
        "diabetes_env.python.conda_dependencies = diabetes_packages\n",
        "\n",
        "# 환경 등록 \r\n",
        "diabetes_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
        "\n",
        "# 파이프라인용 새 runconfig 개체 만들기\r\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# 위에서 만든 컴퓨팅을 사용합니다. \r\n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# 실행 구성에 환경 할당\r\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파이프라인 작성 및 실행\r\n",
        "\r\n",
        "이제 파이프라인을 만들고 실행할 수 있습니다.\r\n",
        "\r\n",
        "먼저 파이프라인용 단계와 파이프라인 간에 전달해야 하는 데이터 참조를 정의해야 합니다. 이 연습의 첫 번째 단계는 두 번째 단계에서 읽을 수 있는 폴더에 준비된 데이터를 써야 합니다. 이 두 단계는 원격 컴퓨팅에서 실행되며 각기 다른 컴퓨팅에서 실행할 수 있으므로, 작업 영역 내 데이터 저장소의 특정 위치에 대한 데이터 참조로 폴더 경로를 전달해야 합니다. **PipelineData** 개체는 중간 스토리지 위치에 사용되며 파이프라인 단계 간에 전달할 수 있는 특수한 종류의 데이터 참조입니다. 여기서는 PipelineData 개체를 만들어 첫 번째 단계의 출력/두 번째 단계의 입력으로 사용할 것입니다. 또한 데이터 참조를 통해 참조하는 데이터 저장소 위치에 코드가 액세스할 수 있도록 이 개체를 스크립트 인수로 전달해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# 학습 데이터 세트 가져오기\r\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# 모델 폴더용 PipelineData(임시 데이터 참조) 만들기\r\n",
        "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n",
        "\n",
        "# 1단계: 데이터 준비 스크립트 실행\r\n",
        "train_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data_folder],\n",
        "                                outputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# 2단계: 학습 스크립트 실행\r\n",
        "register_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-folder', prepped_data_folder],\n",
        "                                inputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 정의한 단계에서 파이프라인을 작성하여 실험으로 실행할 준비가 되었습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# 파이프라인 생성\r\n",
        "pipeline_steps = [train_step, register_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# 실험 작성 및 파이프라인 실행\r\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "파이프라인 실험이 실행되면 위젯에 해당 실험이 그래픽으로 표시됩니다. 페이지 오른쪽 위의 커널 표시기가 **&#9899;**에서 **&#9711;**로 바뀌면 코드 실행이 완료된 것입니다. [Azure Machine Learning Studio](https://ml.azure.com)의 **실험** 페이지에서 파이프라인 실행을 모니터링할 수도 있습니다.\r\n",
        "\r\n",
        "파이프라인이 완료되고 나면 하위 실행에서 기록된 메트릭을 검사할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for run in pipeline_run.get_children():\n",
        "    print(run.name, ':')\n",
        "    metrics = run.get_metrics()\n",
        "    for metric_name in metrics:\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "파이프라인 실행이 정상적으로 완료되면 *학습 컨텍스트* 태그가 지정된 새 모델이 등록됩니다. 이 태그는 해당 모델이 파이프라인에서 학습되었음을 나타냅니다. 다음 코드를 사용하여 모델 등록 여부를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}